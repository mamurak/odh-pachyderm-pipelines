{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "542ade4d-9208-4b5c-aa01-51b502d50ab8",
   "metadata": {},
   "source": [
    "# Open Data Hub + Trino:  <br>  Access and Explore your Data\n",
    "\n",
    "## Introduction\n",
    "**Open Data Hub**, a platform for data scientists and developers of intelligent applications, supports the full Machine Learning lifecycle by providing a robust, scalable platform and a flexible, interactive environment for teams to do their work. \n",
    "\n",
    "**Trino** (formerly PrestoSQL) provides a secure and performant single point of access to all of your data without having to first copy or move it to a central repository. Trino focuses on the first, and often most difficult problem teams face when starting a new project -- the acquisition and preparation of data. With Trino, data scientists and developers will be able to quickly and easily combine data from multiple sources to perform comprehensive analyses for their organizations.\n",
    "\n",
    "This demonstration illustrates how quickly a data scientist can access data and pull it into the Open Data Hub Jupyter environment using Trino."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcc700d-18bb-4584-b8dc-a9b5fff21430",
   "metadata": {},
   "source": [
    "## Installing Required Packages\n",
    "Open Data Hub provides images loaded with popular open source data science packages. These are also the notebook images we use when building our own intelligent applications. \n",
    "\n",
    "While these images typically have everything we need, we can always layer in specific package requirements using `pip` and a `requirements.txt` file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4917fa02-3309-4e0f-bbe3-fb54cb045cde",
   "metadata": {},
   "source": [
    "## Environment Initialization\n",
    "\n",
    "### Import packages and environment variables\n",
    "Let's import the package we installed in the previous step and assign environment variables we included while spawning our notebook. This way, we won't accidentally expose sensitive connection information!\n",
    "\n",
    "Lastly, we use these variables and the `trino.dbapi.connect` function to create our Connection object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b6830c-e694-498d-bbd9-f5e72c3b5e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas\n",
    "import trino\n",
    "\n",
    "\n",
    "TRINO_USERNAME = os.environ.get('TRINO_USERNAME', 'trino')\n",
    "TRINO_PASSWORD = os.environ.get('TRINO_PASSWORD', 'trino')\n",
    "TRINO_HOSTNAME = os.environ.get('TRINO_HOSTNAME', 'trino-service')\n",
    "TRINO_PORT = os.environ.get('TRINO_PORT', '8080')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65788218-cd50-4689-8bf6-8bba06607aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = trino.dbapi.connect(\n",
    "    host=TRINO_HOSTNAME,\n",
    "    port=TRINO_PORT,\n",
    "    user=TRINO_USERNAME,\n",
    "    http_scheme='http',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd69176-0a9a-4e4f-b654-1ff330efb136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql(sql, connector):\n",
    "    \"\"\"Return pandas DataFrame.\"\"\"\n",
    "    \n",
    "    cur = connector.cursor()\n",
    "    cur.execute(sql)\n",
    "    response = pandas.DataFrame(\n",
    "        cur.fetchall(), columns=[c[0] for c in cur.description]\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c48f7-7510-4fd6-a5db-2754d21fa2ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## What is Trino and how does it work? \n",
    "Trino is an incredibly efficient layer sitting between the data consumer and our data sources. It brings our data together so we can query sources individually or join them together in ways that previously required extensive ETL processes.\n",
    "\n",
    "Let's use our connection object and SQL statements to interact with Trino. \n",
    "\n",
    "The following SQL statements help us understand our data sources:\n",
    "* `'SHOW CATALOGS'` shows the data sources available to us at this time,\n",
    "* `'SHOW SCHEMAS'` indicates how data tables are organized, and \n",
    "* `'SHOW TABLES'` exposes datasets within a catalog and schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c04fdaa-1a32-4f11-b70b-86e7c42c1ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'SHOW CATALOGS'\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c124cd-17a6-4c22-81cb-cc7dc5cbaf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'SHOW SCHEMAS from postgresql'\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f52505-2b3c-4b12-9816-0740ab14bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'SHOW TABLES FROM postgresql.pg_catalog'\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6988a2-5c67-4660-894b-f770b1a6cdbe",
   "metadata": {},
   "source": [
    "**Please note**:\n",
    "Your data sources will show up under `'SHOW CATALOGS'` after their respective connectors are configured in your catalog.\n",
    "\n",
    "**Some useful terminology**:\n",
    "* **data source** - your data stored in a database, bucket, or other. Trino has connectors for most sources already. \n",
    "* **connector** - connectors configure your catalog. They give you access to your data sources. They are similar to drivers, in a way.\n",
    "* **catalog** - defines schemas and properties of connections so Trino knows how to query your data.\n",
    "* **schema**  - how your tables are organized.\n",
    "* **table**   - similar to tables in a relational database. A set of rows and columns representing your data based on connector properties.\n",
    "\n",
    "**Useful links**:\n",
    "[Trino Documentation](https://trino.io/docs/current/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb982c0-c31e-401d-92ec-ee94328f2aa8",
   "metadata": {},
   "source": [
    "## Raw data tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dd7737-4e55-428b-88b3-34692358b328",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_to_columns = {\n",
    "    'accounts': ('customer_id', 'snapshotdate', 'Feature_9'),\n",
    "    'demographics': ('customer_id', 'snapshotdate', 'Feature_5', 'Feature_6', 'Feature_7', 'Feature_8'),\n",
    "    'creditcards': ('customer_id', 'snapshotdate', 'Feature_2', 'Feature_3', 'Feature_4'),\n",
    "    'loans': ('customer_id', 'snapshotdate', 'Feature_0', 'Feature_1'),\n",
    "    'labels': ('customer_id', 'snapshotdate', 'label'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af40f1d3-1409-430e-a35e-3aeda78586d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_schema(bucket_name):\n",
    "    print(f'Creating schema for bucket \"{bucket_name}\".')\n",
    "    sql = f\"CREATE SCHEMA hive.{bucket_name} WITH (location = 's3a://{bucket_name}/')\"\n",
    "    df = get_sql(sql, conn)\n",
    "    df.head()\n",
    "\n",
    "\n",
    "def create_table(bucket_name, column_names):\n",
    "    print(f'Creating table for bucket \"{bucket_name}\" with columns \"{column_names}\".')\n",
    "    table_arguments = [\n",
    "        f'{column_name} VARCHAR' for column_name in column_names\n",
    "    ]\n",
    "    table_argument = ','.join(table_arguments)\n",
    "\n",
    "    sql = f\"\"\"\n",
    "    CREATE TABLE hive.{bucket_name}.raw_{bucket_name} ( \n",
    "       {table_argument}\n",
    "    ) WITH ( \n",
    "      EXTERNAL_LOCATION = 's3a://{bucket_name}/',\n",
    "      FORMAT = 'CSV',\n",
    "      skip_header_line_count=1\n",
    "    )\n",
    "\n",
    "    \"\"\"\n",
    "    df = get_sql(sql, conn)\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c15c86-444c-49a4-b820-87fc65d8e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "for bucket_name, column_names in bucket_to_columns.items():\n",
    "    create_schema(bucket_name)\n",
    "    create_table(bucket_name, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550abbd7-7adb-4729-aba3-57f8645a4e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'DESCRIBE hive.creditcards.raw_creditcards'\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927aedfc-5055-4fcd-9540-c3991255c742",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql = 'SELECT * FROM hive.creditcards.raw_creditcards limit 40'\n",
    "df = get_sql(sql, conn)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2d22e0-30a8-4a94-a4db-9bc81e78c05a",
   "metadata": {},
   "source": [
    "## Fact tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d051fa-ada6-4158-885e-0f975c20d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_to_columns = {\n",
    "    'accounts': ('customer_id', 'snapshotdate', 'Feature_9'),\n",
    "    'demographics': ('customer_id', 'snapshotdate', 'Feature_5', 'Feature_6', 'Feature_7', 'Feature_8'),\n",
    "    'creditcards': ('customer_id', 'snapshotdate', 'Feature_2', 'Feature_3', 'Feature_4'),\n",
    "    'loans': ('customer_id', 'snapshotdate', 'Feature_0', 'Feature_1'),\n",
    "    'labels': ('customer_id', 'snapshotdate', 'label'),\n",
    "}\n",
    "\n",
    "column_data_types = {\n",
    "    'customer_id': 'BIGINT',\n",
    "    'snapshotdate': 'VARCHAR',\n",
    "    'label': 'TINYINT',\n",
    "    'Feature_0': 'DOUBLE',\n",
    "    'Feature_1': 'DOUBLE',\n",
    "    'Feature_2': 'DOUBLE',\n",
    "    'Feature_3': 'DOUBLE',\n",
    "    'Feature_4': 'DOUBLE',\n",
    "    'Feature_5': 'DOUBLE',\n",
    "    'Feature_6': 'DOUBLE',\n",
    "    'Feature_7': 'DOUBLE',\n",
    "    'Feature_8': 'DOUBLE',\n",
    "    'Feature_9': 'DOUBLE',    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10487e90-bbd2-4adb-b2b4-ee8c7a0e3ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for renaming existing tables\n",
    "\n",
    "#for table in table_to_columns.keys():\n",
    "#    sql = f'ALTER TABLE postgresql.{table}.fact_{table} RENAME TO postgresql.{table}.fact_{table}_old3'\n",
    "#    df = get_sql(sql, conn)\n",
    "#    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b54911c-d419-4ac8-b2d7-ecb0a4f3ad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_schema(table_name):\n",
    "    print(f'Creating schema for table \"{table_name}\".')\n",
    "    sql = f\"CREATE SCHEMA postgresql.{table_name}\"\n",
    "    df = get_sql(sql, conn)\n",
    "    df.head()\n",
    "\n",
    "\n",
    "def create_table(table_name, column_names):\n",
    "    print(f'Creating table for \"{table_name}\" with columns \"{column_names}\".')\n",
    "    table_arguments = [\n",
    "        f'{column_name} {column_data_types[column_name]}'\n",
    "        for column_name in column_names\n",
    "    ]\n",
    "    table_argument = ','.join(table_arguments)\n",
    "\n",
    "    sql = f\"\"\"\n",
    "    CREATE TABLE postgresql.{table_name}.fact_{table_name} ( \n",
    "       {table_argument}\n",
    "    )\n",
    "\n",
    "    \"\"\"\n",
    "    df = get_sql(sql, conn)\n",
    "    df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ccd8f2-bfb2-42ab-83f3-06b9c7eabe73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for table_name, column_names in table_to_columns.items():\n",
    "    create_schema(table_name)\n",
    "    create_table(table_name, column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab474f39-c5cb-467e-8f1e-ff6abc40f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'DESCRIBE postgresql.loans.fact_loans'\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dd68b7-1028-4f6e-b667-673ba1175018",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'SELECT * FROM postgresql.loans.fact_loans limit 40'\n",
    "df = get_sql(sql, conn)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc09fa8-aeee-4469-9b33-485f5b29f42b",
   "metadata": {},
   "source": [
    "## Analytical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4b14ab-0e9b-4c03-bd76-86b4666ed5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Creating schema for analytical dataset.')\n",
    "sql = f\"CREATE SCHEMA postgresql.analytical_dataset\"\n",
    "df = get_sql(sql, conn)\n",
    "df.head()\n",
    "\n",
    "print(f'Creating table for the analytical dataset with columns \"{column_data_types.items()}\".')\n",
    "table_arguments = [\n",
    "        f'{column_name} {data_type}'\n",
    "        for column_name, data_type in column_data_types.items()\n",
    "    ]\n",
    "table_argument = ','.join(table_arguments)\n",
    "\n",
    "sql = f\"\"\"\n",
    "CREATE TABLE postgresql.analytical_dataset.analytical_dataset ( \n",
    "   {table_argument}\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "print(f'Running query against Trino : {sql}')\n",
    "df = get_sql(sql, conn)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b4765-5fa7-4138-bc0d-cd3af13d7c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'DESCRIBE postgresql.analytical_dataset.analytical_dataset'\n",
    "df = get_sql(sql, conn)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0604e38-36d9-4fb9-bf7b-e9082d8ecb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = 'SELECT * FROM postgresql.analytical_dataset.analytical_dataset limit 40'\n",
    "df = get_sql(sql, conn)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "dependency_resolution_engine": "pipenv",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "requirements": "{\"packages\":{\"trino\":\"*\",\"boto3\":\"*\"},\"requires\":{\"python_version\":\"3.8\"},\"source\":[{\"name\":\"pypi\",\"url\":\"https://pypi.org/simple\",\"verify_ssl\":true}]}",
  "requirements_lock": "{\"_meta\":{\"sources\":[{\"url\":\"https://pypi.org/simple\",\"verify_ssl\":true,\"name\":\"pypi\"}],\"requires\":{\"python_version\":\"3.8\"},\"hash\":{\"sha256\":\"6e80728e57562982efed6a2842155743c7fed9d663e0d8a1b29a9a1a820901a1\"},\"pipfile-spec\":6},\"default\":{\"boto3\":{\"version\":\"==1.24.48\",\"hashes\":[\"sha256:632676a480854d7c18ae634e2e83a93dc27211b88e19340e047bbd432128819e\",\"sha256:db27c33a7ccccbf76035ab47e92054ce8ab98b809cf49eb15a2502eedc3ba332\"],\"index\":\"pypi\"},\"botocore\":{\"version\":\"==1.27.48\",\"hashes\":[\"sha256:5958ef6dd3b0f84eb1ee0aac75499ac504fcc0787fd6611be727968d51dcbfa7\",\"sha256:8de2f4285046ed306439723a11706067d6901c3f7be418b7b104ba8e002b5638\"],\"markers\":\"python_version >= '3.7'\"},\"certifi\":{\"version\":\"==2022.6.15\",\"hashes\":[\"sha256:84c85a9078b11105f04f3036a9482ae10e4621616db313fe045dd24743a0820d\",\"sha256:fe86415d55e84719d75f8b69414f6438ac3547d2078ab91b67e779ef69378412\"],\"markers\":\"python_full_version >= '3.6.0'\"},\"charset-normalizer\":{\"version\":\"==2.1.0\",\"hashes\":[\"sha256:5189b6f22b01957427f35b6a08d9a0bc45b46d3788ef5a92e978433c7a35f8a5\",\"sha256:575e708016ff3a5e3681541cb9d79312c416835686d054a23accb873b254f413\"],\"markers\":\"python_full_version >= '3.6.0'\"},\"idna\":{\"version\":\"==3.3\",\"hashes\":[\"sha256:84d9dd047ffa80596e0f246e2eab0b391788b0503584e8945f2368256d2735ff\",\"sha256:9d643ff0a55b762d5cdb124b8eaa99c66322e2157b69160bc32796e824360e6d\"],\"markers\":\"python_version >= '3.5'\"},\"jmespath\":{\"version\":\"==1.0.1\",\"hashes\":[\"sha256:02e2e4cc71b5bcab88332eebf907519190dd9e6e82107fa7f83b1003a6252980\",\"sha256:90261b206d6defd58fdd5e85f478bf633a2901798906be2ad389150c5c60edbe\"],\"markers\":\"python_version >= '3.7'\"},\"python-dateutil\":{\"version\":\"==2.8.2\",\"hashes\":[\"sha256:0123cacc1627ae19ddf3c27a5de5bd67ee4586fbdd6440d9748f8abb483d3e86\",\"sha256:961d03dc3453ebbc59dbdea9e4e11c5651520a876d0f4db161e8674aae935da9\"],\"markers\":\"python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'\"},\"pytz\":{\"version\":\"==2022.1\",\"hashes\":[\"sha256:1e760e2fe6a8163bc0b3d9a19c4f84342afa0a2affebfaa84b01b978a02ecaa7\",\"sha256:e68985985296d9a66a881eb3193b0906246245294a881e7c8afe623866ac6a5c\"]},\"requests\":{\"version\":\"==2.28.1\",\"hashes\":[\"sha256:7c5599b102feddaa661c826c56ab4fee28bfd17f5abca1ebbe3e7f19d7c97983\",\"sha256:8fefa2a1a1365bf5520aac41836fbee479da67864514bdb821f31ce07ce65349\"],\"markers\":\"python_version >= '3.7' and python_version < '4'\"},\"s3transfer\":{\"version\":\"==0.6.0\",\"hashes\":[\"sha256:06176b74f3a15f61f1b4f25a1fc29a4429040b7647133a463da8fa5bd28d5ecd\",\"sha256:2ed07d3866f523cc561bf4a00fc5535827981b117dd7876f036b0c1aca42c947\"],\"markers\":\"python_version >= '3.7'\"},\"six\":{\"version\":\"==1.16.0\",\"hashes\":[\"sha256:1e61c37477a1626458e36f7b1d82aa5c9b094fa4802892072e49de9c60c4c926\",\"sha256:8abb2f1d86890a2dfb989f9a77cfcfd3e47c2a354b01111771326f8aa26e0254\"],\"markers\":\"python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3'\"},\"trino\":{\"version\":\"==0.315.0\",\"hashes\":[\"sha256:a48baaf327718e60aa4b208a32469ecde068b100c1c4027690a583497dd9a5c8\",\"sha256:b10f40e9d178602b39463adb57c207a6c1803eb1a8ecb8cc9d5e710cf3dfbbc7\"],\"index\":\"pypi\"},\"urllib3\":{\"version\":\"==1.26.11\",\"hashes\":[\"sha256:c33ccba33c819596124764c23a97d25f32b28433ba0dedeb77d873a38722c9bc\",\"sha256:ea6e8fb210b19d950fab93b60c9009226c63a28808bc8386e05301e25883ac0a\"],\"markers\":\"python_version >= '2.7' and python_version not in '3.0, 3.1, 3.2, 3.3, 3.4, 3.5' and python_version < '4'\"}},\"develop\":{}}"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
